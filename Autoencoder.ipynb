{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "from_pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VyatkinAlexey/Noiseless/blob/master/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itNh6SeTfkir",
        "colab_type": "text"
      },
      "source": [
        "# Машинный перевод с помощью openNMT для соревнования STAPLE от Duolingo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GolaUOBhf-A2",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка данных. \n",
        "\n",
        "Так как данных предоставленных орагнизаторами явно недостаточно для того чтобы обучить полноценную языковую модель, для каждого из 5 языков были загружены параллельные корпуса субтитров. (http://opus.nlpl.eu/OpenSubtitles-v2016.php) Данные можно также найти на сервере nlp1 в папке `voronov/data/OpenSubtitles`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQG_NetqIko",
        "colab_type": "code",
        "outputId": "0def144a-c9b0-4e9f-9968-23b45745df6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "# this is for colab skip if you don't need to connect to drive)\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "course = 'en_vi'\n",
        "path_to_corpora = os.path.join('/content/gdrive/My Drive/data/work/Panchenko/corpora/OpenSubtitles/', course)\n",
        "path_to_duolingo = os.path.join('/content/gdrive/My Drive/data/work/Panchenko/duolingo/data/', course)\n",
        "path_to_model = os.path.join('/content/gdrive/My Drive/data/work/Panchenko/language_models', course)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zduzEh15reOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(path_to_corpora) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOJD30m1rH8G",
        "colab_type": "code",
        "outputId": "e352e3c9-bdbf-48fd-9284-98ba94e8e480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/moses/en-ko.txt.zip\n",
        "!unzip  'download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-25 14:12:00--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/moses/en-ko.txt.zip\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/moses/en-ko.txt.zip [following]\n",
            "--2020-03-25 14:12:00--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/moses/en-ko.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12433629 (12M) [application/zip]\n",
            "Saving to: ‘download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip’\n",
            "\n",
            "\r          download.   0%[                    ]       0  --.-KB/s               \r         download.p   5%[>                   ] 691.75K  3.02MB/s               \r        download.ph  88%[================>   ]  10.55M  24.8MB/s               \rdownload.php?f=Open 100%[===================>]  11.86M  26.1MB/s    in 0.5s    \n",
            "\n",
            "2020-03-25 14:12:01 (26.1 MB/s) - ‘download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip’ saved [12433629/12433629]\n",
            "\n",
            "Archive:  download.php?f=OpenSubtitles%2Fv2016%2Fmoses%2Fen-ko.txt.zip\n",
            "  inflating: OpenSubtitles.en-ko.en  \n",
            "  inflating: OpenSubtitles.en-ko.ko  \n",
            "  inflating: OpenSubtitles.en-ko.ids  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qWWJBpps_-v",
        "colab_type": "text"
      },
      "source": [
        "Для правильного запуска openNMT понадобится разбить данные на трейн часть и на валидационную. Я решил использовать всего 1 миллион пар предложений (для корейского языка всего было доступно только 370 тысяч предложений) для обучения и 5000 пар для валидации (это не в прямом смысле валидация, она нужна только для корректной работы скриптов openNMT, в их руководстве сказано, что 5000 будет достаточно)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPEv998CTtl",
        "colab_type": "code",
        "outputId": "7f68c26b-f28e-42ad-f589-0afcb0dd5dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!wc -l OpenSubtitles.en-ko.en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "370702 OpenSubtitles.en-ko.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxn2nykatlXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n 365000 'OpenSubtitles.en-ko.en' > 'train_subtitles_1m_en.txt'\n",
        "!head -n 365000 'OpenSubtitles.en-ko.ko' > 'train_subtitles_1m_ko.txt'\n",
        "!tail -n 5000 'OpenSubtitles.en-ko.en' > 'dev_subtitles_en.txt'\n",
        "!tail -n 5000 'OpenSubtitles.en-ko.ko' > 'dev_subtitles_ko.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCloP520MCl-",
        "colab_type": "text"
      },
      "source": [
        "## Данные Duolingo\n",
        "\n",
        "Для составления предсказания для соревнования Duolingo я взял файл формата `*.aws_baseline.pred.txt`, который содержит по одному референсному переводу от Amazon для каждого предложения, предобработал его (убрал префиксы у строчек, соединил строчки \"сообщение-перевод\" в одну, разделённую табом, удалил пустые строчки) и разбил на два файла: с исходным языком и таргетным. Для того чтобы на стадии предсказания точно не возникло незнакомых для модели слов, я добавил полученные файлы в обучающую выборку."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0pRNrQsNCuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(os.path.join(path_to_duolingo, 'train'))\n",
        "#remove all markers | remove blank lines | combine every two lines in one\n",
        "#!sed 's/.*|//g' train.en_hu.aws_baseline.pred.txt | grep . | paste -d \"\\t\"  - - > train_duolingo_en_hu.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljv8pWxNOr8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train_duolingo_en_ko.txt') as f, open('train_duolingo_en.txt', 'w') as file_en, \\\n",
        "open('train_duolingo_ko.txt', 'w') as file_ko:\n",
        "    for line in f.readlines():\n",
        "        pair = line.strip().split('\\t')\n",
        "        file_en.writelines(pair[0]+'\\n')\n",
        "        file_ko.writelines(pair[1]+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZewWVEqpSSdb",
        "colab_type": "code",
        "outputId": "aa5c7685-4951-4fda-bb0d-d7e4c0692c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!tail -5 ../../../../corpora/OpenSubtitles/en_ko/train_subtitles_1m_en.txt\n",
        "!cat train_duolingo_en.txt >> ../../../../corpora/OpenSubtitles/en_ko/train_subtitles_1m_en.txt\n",
        "!cat train_duolingo_ko.txt >> ../../../../corpora/OpenSubtitles/en_ko/train_subtitles_1m_ko.txt\n",
        "!tail -5 ../../../../corpora/OpenSubtitles/en_ko/train_subtitles_1m_en.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Again, nothing witchy.\n",
            "Ghost?\n",
            "Hard to say.\n",
            "I mean, there's EMF in the church, but it's built on a burial ground.\n",
            "You know that all the victims recently went to confession?\n",
            "english is an international language.\n",
            "which floor is it?\n",
            "the waiter has asked everybody.\n",
            "it is a beautiful bird.\n",
            "i count.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0SfVDu7uzDD",
        "colab_type": "text"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXzIhLk8llEW",
        "colab_type": "code",
        "outputId": "c5fbd7d3-d4d3-4b9d-9c91-7dbada3447c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: tqdm~=4.30.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (4.30.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /tensorflow-1.15.0/python3.6 (from OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n",
            "Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied: pyonmttok==1.*; platform_system == \"Linux\" in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.18.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1.1)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.18.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (46.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->OpenNMT-py) (2.21.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (2.11.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py) (2019.11.28)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUyj_tdgz0Hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(os.path.join(path_to_model, 'openNMT'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l9CKGY600We",
        "colab_type": "code",
        "outputId": "5b3af464-870e-4ee4-f6f3-ec04a6bda4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "!onmt_preprocess -train_src ../../../corpora/OpenSubtitles/en_vi/train_subtitles_1m_en.txt \\\n",
        "-train_tgt ../../../corpora/OpenSubtitles/en_vi/train_subtitles_1m_vi.txt \\\n",
        "-valid_src ../../../corpora/OpenSubtitles/en_vi/dev_subtitles_en.txt \\\n",
        "-valid_tgt ../../../corpora/OpenSubtitles/en_vi/dev_subtitles_vi.txt \\\n",
        "-tgt_vocab_size 50000 -src_vocab_size 50000 --src_seq_length 25 --tgt_seq_length 25 \\\n",
        "-save_data nmt_subs_en_vi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-03-26 12:23:25,754 INFO] Extracting features...\n",
            "[2020-03-26 12:23:26,631 INFO]  * number of source features: 0.\n",
            "[2020-03-26 12:23:26,632 INFO]  * number of target features: 0.\n",
            "[2020-03-26 12:23:26,632 INFO] Building `Fields` object...\n",
            "[2020-03-26 12:23:26,633 INFO] Building & saving training data...\n",
            "[2020-03-26 12:23:29,506 INFO] Building shard 0.\n",
            "[2020-03-26 12:24:09,090 INFO]  * saving 0th train data shard to nmt_subs_en_vi.train.0.pt.\n",
            "[2020-03-26 12:24:32,843 INFO] Building shard 1.\n",
            "[2020-03-26 12:24:32,987 INFO]  * saving 1th train data shard to nmt_subs_en_vi.train.1.pt.\n",
            "[2020-03-26 12:24:33,406 INFO]  * tgt vocab size: 50004.\n",
            "[2020-03-26 12:24:33,731 INFO]  * src vocab size: 50002.\n",
            "[2020-03-26 12:24:34,575 INFO] Building & saving validation data...\n",
            "[2020-03-26 12:24:35,621 INFO] Building shard 0.\n",
            "[2020-03-26 12:24:35,778 INFO]  * saving 0th valid data shard to nmt_subs_en_vi.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-dtRaDayJS2",
        "colab_type": "text"
      },
      "source": [
        "Это облегченная модель трансформера (чтобы обучение занимало адекватное время (~12 часов). Я уменьшил `rnn_size`, `word_vec_size`, `heads`, `training_steps` в 2 раза. Остальное оставил таким же как указано в рекомендациях openNMT, которые якобы повторяют исходный сетап Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpkCSmAIJ-_z",
        "colab_type": "code",
        "outputId": "dd40bcec-9e34-4af4-c537-c09b7175007a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!onmt_train -data nmt_subs_en_vi -save_model transformer \\\n",
        "        -layers 6 -rnn_size 256 -word_vec_size 256 -transformer_ff 2048 -heads 4  \\\n",
        "        -encoder_type transformer -decoder_type transformer -position_encoding \\\n",
        "        -train_steps 100000  -max_generator_batches 2 -dropout 0.1 \\\n",
        "        -batch_size 4096 -batch_type tokens -normalization tokens  -accum_count 2 \\\n",
        "        -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 \\\n",
        "        -max_grad_norm 0 -param_init 0  -param_init_glorot \\\n",
        "        -label_smoothing 0.1 -valid_steps 10000 -save_checkpoint_steps 5000 \\\n",
        "        -world_size 1 -gpu_ranks 0\n",
        "# i omitted output with training statistics for better representation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-03-26 12:25:40,102 INFO]  * src vocab size = 50002\n",
            "[2020-03-26 12:25:40,102 INFO]  * tgt vocab size = 50004\n",
            "[2020-03-26 12:25:40,103 INFO] Building model...\n",
            "[2020-03-26 12:25:49,045 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50002, 256, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50004, 256, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=50004, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-03-26 12:25:49,108 INFO] encoder: 20691456\n",
            "[2020-03-26 12:25:49,108 INFO] decoder: 35125076\n",
            "[2020-03-26 12:25:49,108 INFO] * number of parameters: 55816532\n",
            "[2020-03-26 12:25:49,117 INFO] Starting training on GPU: [0]\n",
            "[2020-03-26 12:25:49,117 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-03-26 12:25:49,117 INFO] Loading dataset from nmt_subs_en_vi.train.0.pt\n",
            "[2020-03-26 12:25:58,894 INFO] number of examples: 986019\n",
            "[2020-03-26 12:27:20,827 INFO] Step 50/100000; acc:   5.92; ppl: 11543.40; xent: 9.35; lr: 0.00001; 2775/4105 tok/s;     92 sec\n",
            "[2020-03-26 12:28:30,696 INFO] Step 100/100000; acc:  11.45; ppl: 9366.79; xent: 9.14; lr: 0.00002; 4000/5389 tok/s;    162 sec\n",
            "[2020-03-26 12:29:38,511 INFO] Step 150/100000; acc:  12.37; ppl: 6888.31; xent: 8.84; lr: 0.00003; 3868/5407 tok/s;    229 sec\n",
            "[2020-03-26 12:30:48,387 INFO] Step 200/100000; acc:  12.52; ppl: 4523.11; xent: 8.42; lr: 0.00004; 3809/5440 tok/s;    299 sec\n",
            "[2020-03-26 12:31:55,701 INFO] Step 250/100000; acc:  13.72; ppl: 2702.20; xent: 7.90; lr: 0.00004; 3997/5402 tok/s;    367 sec\n",
            "[2020-03-26 12:33:04,115 INFO] Step 300/100000; acc:  13.15; ppl: 1583.41; xent: 7.37; lr: 0.00005; 3876/5365 tok/s;    435 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0B6UaaaPd2x",
        "colab_type": "text"
      },
      "source": [
        "Теперь у нас есть модель-переводчик, исходный текст для перевода и их референсный перевод от Amazon. Для примера выведем 10 лучших переводов одного предложения (автоматическое определение правильного числа переводов для каждого предложения -- потом)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dqwyjbkACNV",
        "colab_type": "code",
        "outputId": "77513e03-8b37-4fb2-f08b-e458eaf83250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!onmt_translate -model transformer_step_70000.pt -src ../../../duolingo/data/en_pt/train/train_duolingo_en.txt \\\n",
        "-output train_duolingo_pred10_pt.txt -n_best 10 -replace_unk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-03-18 15:51:10,744 INFO] Translating shard 0.\n",
            "PRED AVG SCORE: -0.5227, PRED PPL: 1.6865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFhX5iEPbj3",
        "colab_type": "code",
        "outputId": "d496e736-a374-4872-f63c-a25909a43295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!head -n 20 train_duolingo_pred10_pt.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se video com o video\n",
            "Se importaria se video o video\n",
            "Se importaria de trocar esse colar para mim?\n",
            "Se importaria se eu video esse video\n",
            "Se importaria se video com o video\n",
            "Se importaria se video com o segundo para mim?\n",
            "Se importaria se video com o segundo melhor para mim?\n",
            "Se importaria se video com o segundo melhor video\n",
            "Se importaria se video com o segundo melhor passeio para mim?\n",
            "Se importaria se video com o segundo melhor passeio por mim?\n",
            "A livraria não está nesta rua.\n",
            "A livraria não está nesta estrada.\n",
            "A livraria não está nessa rua.\n",
            "- A livraria não está nesta rua.\n",
            "A livraria não está aqui.\n",
            "- A livraria não está nesta estrada.\n",
            "- A livraria não está nesta rua. isn't\n",
            "- A livraria não está nesta rua. - Sim.\n",
            "- A livraria não está nesta rua. Não está aqui.\n",
            "- A livraria não está nesta rua. - Está na rua.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpX2A0SIUO3K",
        "colab_type": "text"
      },
      "source": [
        "## TODO: Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvJtsDEnBu8n",
        "colab_type": "code",
        "outputId": "06cf10d7-c445-43d6-8035-1ac87610bd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\"\"\"from nltk.translate.bleu_score import corpus_bleu\n",
        "import re\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "with open('../../duolingo/data/en-pt/train/train_duolingo_pt.txt') as gold:\n",
        "    for sentence in gold.readlines():\n",
        "        s = ' '.join(re.split(r'([^0-9a-zÀ-ÿ\\s])',sentence.lower()))\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "        references.append(s.split())\n",
        "with open('openNMT/train_duolingo_pred_pt.txt') as preds:\n",
        "    for sentence in preds.readlines():\n",
        "        s = ' '.join(re.split(r'([^0-9a-zÀ-ÿ\\s])',sentence.lower()))\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "        predictions.append(s.split())\n",
        "print(predictions[1])\n",
        "print(references[1])\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'livraria', 'não', 'está', 'nesta', 'rua', '.']\n",
            "['a', 'livraria', 'não', 'é', 'nesta', 'rua', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNkR-xmE3-1",
        "colab_type": "code",
        "outputId": "58774ac3-251d-40a2-f730-cb924075e6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# corpus_bleu(references, predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6902782199046656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRSePtAJrRcv",
        "colab_type": "code",
        "outputId": "421addeb-2368-44d9-c8ec-f42be08e2c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "!less 'train_subtitles_1m_en.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b7\u001b[?47h\u001b[?1h\u001b=\rMale narrator: Next, on Ice Road Truckers...\r\n",
            "Welcome to the twilight zone\r\n",
            "Again.\r\n",
            "Narrator: The pressure is on\r\n",
            "For lisa's most important run of\r\n",
            "The season.\r\n",
            "I think I'm ready to kind of Step up the game a little bit.\r\n",
            "Narrator: Two ice road Veterans get ready to throw\r\n",
            "Down. I'm not here to make friends,\r\n",
            "I'm here to ke money. Narrator: And a monster storm\r\n",
            "Smashes into atigun pass. I'm gonna get this tank there\r\n",
            "Tonight, storm or no storm. Narrator: Turning the dash\r\n",
            "For the cash into a fight for\r\n",
            "Survival.\r\n",
            "We're at the eye of the Storm, the mouth of the beast. The way it looks here, we\r\n",
            "Narrator: 50 miles outside\r\n",
            "Of prudhoe bay...\r\n",
            "Alex debogorski is headed south On the vast, open tundra of the\r\n",
            "North slope.\r\n",
            "Weather changes quickly across The flat planes. And, for the second week in a\r\n",
            "Row, alex finds himself in the\r\n",
            "Middle of a blinding snowstorm.\r\n",
            "Yep, she's starting to get\n",
            "\u001b[KWorse in here.\n",
            "\u001b[KWell, you can see the fingers of Snow, the little snowdrifts\n",
            "\u001b[KInto the road.\n",
            "\u001b[K\u001b[?1l\u001b>\u001b[2J\u001b[?47l\u001b8"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOX5E-znHk6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = ''\n",
        "with open('train_subtitles_1m_en.txt') as source, open('my_version_en.txt', 'w') as target:\n",
        "    for i, line in enumerate(source.readlines()):\n",
        "        if i==50:\n",
        "            break\n",
        "        line = line.strip().lower()\n",
        "        temp += line + ' '\n",
        "        sentences = temp.split('.')\n",
        "        if len(sentences) > 1:\n",
        "            if sentences[-1][-1] != '.':\n",
        "                temp = sentences[-1][-1]\n",
        "                for sentence in sentences[:-1]:\n",
        "                    \n",
        "            else:\n",
        "                for sentence in sentences:\n",
        "                    target.writeline(sentence+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gbJs7f5Jx8D",
        "colab_type": "code",
        "outputId": "4876f9e8-0461-4d26-8053-7d071f2f10ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!head 'my_version_en.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "male narrator: next, on ice road truckers... \n",
            "welcome to the twilight zone again. \n",
            "narrator: the pressure is on for lisa's most important run of the season. \n",
            "i think i'm ready to kind of step up the game a little bit. \n",
            "narrator: two ice road veterans get ready to throw down. i'm not here to make friends, i'm here to ke money. narrator: and a monster storm smashes into atigun pass. i'm gonna get this tank there tonight, storm or no storm. narrator: turning the dash for the cash into a fight for survival. \n",
            "we're at the eye of the storm, the mouth of the beast. the way it looks here, we narrator: 50 miles outside of prudhoe bay... \n",
            "alex debogorski is headed south on the vast, open tundra of the north slope. \n",
            "weather changes quickly across the flat planes. and, for the second week in a row, alex finds himself in the middle of a blinding snowstorm. \n",
            "yep, she's starting to get worse in here. \n",
            "well, you can see the fingers of snow, the little snowdrifts into the road. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxv1-gopJ4j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}